{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/LeanManager/NLP-PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN/LSTN: input (xt) => hidden state (ht)\n",
    "\n",
    "lstm = nn.LSTM (input_size = input_dimension,\n",
    "                hiden_size = hiden_dimension,\n",
    "                num_layers = n_layers)\n",
    "                \n",
    "out, hidden = lstm (input, (h0, c0))\n",
    "\n",
    "input = tensor containing the values in an input sequence (seq_len, batch, input_size)\n",
    "\n",
    "h0 = a tensor containing the initial hidden state for each element in a batch\n",
    "c0 = a tensor containing the initial cell memory for each element in the batch\n",
    "h0 and c0 will default to 0, their dimension are (n_layers*n_directions, batch, hidden_dim)\n",
    "\n",
    "all of the weights are actually the same as that RNN cell is essentially being re-used throughout the process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as  np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN/LSTM structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: \n",
      " [tensor([[ 1.4585, -0.2669,  0.2690, -0.5728]]), tensor([[ 2.2614, -0.5147,  0.5446, -1.4257]]), tensor([[-9.9630e-01,  1.2686e+00, -2.2741e+00,  2.0916e-03]]), tensor([[ 0.8580, -1.5871, -0.8145,  0.2116]]), tensor([[ 1.0238,  0.4050,  0.4375, -0.1857]])]\n",
      "\n",
      "\n",
      "tensor([[[ 1.4585, -0.2669,  0.2690, -0.5728]]])\n",
      "out: \n",
      " tensor([[[-0.1022,  0.5371, -0.3542]]], grad_fn=<StackBackward>)\n",
      "hidden: \n",
      " (tensor([[[-0.1022,  0.5371, -0.3542]]], grad_fn=<StackBackward>), tensor([[[-0.2796,  1.0876, -0.6428]]], grad_fn=<StackBackward>))\n",
      "\n",
      "\n",
      "tensor([[[ 2.2614, -0.5147,  0.5446, -1.4257]]])\n",
      "out: \n",
      " tensor([[[-0.1006,  0.6589, -0.4412]]], grad_fn=<StackBackward>)\n",
      "hidden: \n",
      " (tensor([[[-0.1006,  0.6589, -0.4412]]], grad_fn=<StackBackward>), tensor([[[-0.4406,  1.2990, -0.6963]]], grad_fn=<StackBackward>))\n",
      "\n",
      "\n",
      "tensor([[[-9.9630e-01,  1.2686e+00, -2.2741e+00,  2.0916e-03]]])\n",
      "out: \n",
      " tensor([[[0.0839, 0.4869, 0.2786]]], grad_fn=<StackBackward>)\n",
      "hidden: \n",
      " (tensor([[[0.0839, 0.4869, 0.2786]]], grad_fn=<StackBackward>), tensor([[[0.1044, 1.0523, 0.4152]]], grad_fn=<StackBackward>))\n",
      "\n",
      "\n",
      "tensor([[[ 0.8580, -1.5871, -0.8145,  0.2116]]])\n",
      "out: \n",
      " tensor([[[-0.1105,  0.1851, -0.2023]]], grad_fn=<StackBackward>)\n",
      "hidden: \n",
      " (tensor([[[-0.1105,  0.1851, -0.2023]]], grad_fn=<StackBackward>), tensor([[[-0.3030,  0.4528, -0.3340]]], grad_fn=<StackBackward>))\n",
      "\n",
      "\n",
      "tensor([[[ 1.0238,  0.4050,  0.4375, -0.1857]]])\n",
      "out: \n",
      " tensor([[[-0.0447,  0.5888, -0.2301]]], grad_fn=<StackBackward>)\n",
      "hidden: \n",
      " (tensor([[[-0.0447,  0.5888, -0.2301]]], grad_fn=<StackBackward>), tensor([[[-0.0901,  1.3514, -0.4667]]], grad_fn=<StackBackward>))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_dim = 4\n",
    "hidden_dim = 3\n",
    "\n",
    "lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim)\n",
    "\n",
    "inputs_list = [torch.randn(1, input_dim) for _ in range (5)]\n",
    "print ('inputs: \\n', inputs_list)\n",
    "print ('\\n')\n",
    "\n",
    "h0 = torch.randn(1,1,hidden_dim)\n",
    "c0 = torch.randn(1,1,hidden_dim)\n",
    "\n",
    "for i in inputs_list:\n",
    "    out, hidden = lstm(i.view(1,1,-1),(h0,c0))\n",
    "    \n",
    "    print(i.view(1,1,-1))\n",
    "    print('out: \\n', out)\n",
    "    print('hidden: \\n', hidden)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: \n",
      " torch.Size([5, 1, 4])\n",
      "\n",
      "\n",
      "inputs: \n",
      " tensor([[[ 1.4585e+00, -2.6691e-01,  2.6902e-01, -5.7277e-01]],\n",
      "\n",
      "        [[ 2.2614e+00, -5.1467e-01,  5.4460e-01, -1.4257e+00]],\n",
      "\n",
      "        [[-9.9630e-01,  1.2686e+00, -2.2741e+00,  2.0916e-03]],\n",
      "\n",
      "        [[ 8.5801e-01, -1.5871e+00, -8.1452e-01,  2.1161e-01]],\n",
      "\n",
      "        [[ 1.0238e+00,  4.0501e-01,  4.3746e-01, -1.8571e-01]]])\n",
      "\n",
      "\n",
      "out: \n",
      " tensor([[[ 2.6436e-02,  4.9025e-01,  3.8313e-01]],\n",
      "\n",
      "        [[-2.1447e-02,  4.7132e-01,  7.3166e-02]],\n",
      "\n",
      "        [[ 1.9291e-01,  2.4376e-01,  3.7812e-01]],\n",
      "\n",
      "        [[-9.3205e-03, -2.4383e-02,  5.7246e-02]],\n",
      "\n",
      "        [[ 2.8757e-04,  1.0533e-01, -2.5121e-02]]], grad_fn=<StackBackward>)\n",
      "torch.Size([5, 1, 3])\n",
      "hidden: \n",
      " (tensor([[[ 0.0003,  0.1053, -0.0251]]], grad_fn=<StackBackward>), tensor([[[ 0.0008,  0.1728, -0.0662]]], grad_fn=<StackBackward>))\n"
     ]
    }
   ],
   "source": [
    "#using batches\n",
    "\n",
    "inputs = torch.cat(inputs_list).view(len(inputs_list),1,-1)\n",
    "\n",
    "print('input size: \\n', inputs.size())\n",
    "print('\\n')\n",
    "\n",
    "print('inputs: \\n', inputs)\n",
    "print('\\n')\n",
    "\n",
    "h0 = torch.randn(1,1,hidden_dim)\n",
    "c0 = torch.randn(1,1,hidden_dim)\n",
    "\n",
    "out, hidden = lstm(inputs,(h0,c0))\n",
    "\n",
    "print('out: \\n', out)\n",
    "print(out.shape)\n",
    "print('hidden: \\n', hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM part-of-speech tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "    (\"The cat ate the cheese\".lower().split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"She read that book\".lower().split(), [\"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"The dog loves art\".lower().split(), [\"DET\", \"NN\", \"V\", \"NN\"]),\n",
    "    (\"The elephant answers the phone\".lower().split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]\n",
    "\n",
    "word2idx = {}\n",
    "\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = len(word2idx)\n",
    "            \n",
    "tag2idx = {\"DET\":0, \"NN\":1, \"V\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 0, 'cat': 1, 'ate': 2, 'cheese': 3, 'she': 4, 'read': 5, 'that': 6, 'book': 7, 'dog': 8, 'loves': 9, 'art': 10, 'elephant': 11, 'answers': 12, 'phone': 13}\n"
     ]
    }
   ],
   "source": [
    "print (word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_idx):\n",
    "\n",
    "    \n",
    "    idxs = [to_idx[w] for w in seq]\n",
    "    idxs = np.array(idxs)\n",
    "    \n",
    "    return torch.from_numpy(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  8, 12,  0, 13])\n"
     ]
    }
   ],
   "source": [
    "exemple_input = prepare_sequence(\"The dog answers the phone\".lower().split(),word2idx)\n",
    "\n",
    "print(exemple_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        ''' Initialize the layers of this model.'''\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # embedding layer that turns words into a vector of a specified size\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # the LSTM takes embedded word vectors (of a specified size) as inputs \n",
    "        # and outputs hidden states of size hidden_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # the linear layer that maps the hidden state output dimension \n",
    "        # to the number of tags we want as output, tagset_size (in this case this is 3 tags)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        \n",
    "        # initialize the hidden state (see code below)\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        ''' At the start of training, we need to initialize a hidden state;\n",
    "           there will be none because the hidden state is formed based on perviously seen data.\n",
    "           So, this function defines a hidden state with all zeroes and of a specified size.'''\n",
    "        # The axes dimensions are (n_layers, batch_size, hidden_dim)\n",
    "        return (torch.zeros(1, 1, self.hidden_dim),\n",
    "                torch.zeros(1, 1, self.hidden_dim))\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        ''' Define the feedforward behavior of the model.'''\n",
    "        # create embedded word vectors for each word in a sentence\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        \n",
    "        # get the output and hidden state by passing the lstm over our word embeddings\n",
    "        # the lstm takes in our embeddings and hiddent state\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "            embeds.view(len(sentence), 1, -1), self.hidden)\n",
    "        \n",
    "        # get the scores for the most likely tag for a word\n",
    "        tag_outputs = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_outputs, dim=1)\n",
    "        \n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6\n",
    "\n",
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word2idx), len(tag2idx))\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMTagger(\n",
       "  (word_embeddings): Embedding(14, 6)\n",
       "  (lstm): LSTM(6, 6)\n",
       "  (hidden2tag): Linear(in_features=6, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0175, -1.0981, -1.1875],\n",
      "        [-1.0282, -1.0665, -1.2102],\n",
      "        [-0.9977, -1.1115, -1.1967],\n",
      "        [-1.0327, -1.0965, -1.1714],\n",
      "        [-1.0477, -1.0595, -1.1953]], grad_fn=<LogSoftmaxBackward>)\n",
      "\n",
      "\n",
      "predicted tags: \n",
      " tensor([0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"The cheese loves the elephant\".lower().split()\n",
    "\n",
    "inputs = prepare_sequence(test_sentence, word2idx)\n",
    "inputs = inputs\n",
    "tag_scores = model(inputs)\n",
    "print(tag_scores)\n",
    "\n",
    "_, predicted_tags = torch.max(tag_scores, 1)\n",
    "print('\\n')\n",
    "print('predicted tags: \\n', predicted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, loss: 1.01532\n",
      "Epoch: 40, loss: 0.91809\n",
      "Epoch: 60, loss: 0.75323\n",
      "Epoch: 80, loss: 0.60342\n",
      "Epoch: 100, loss: 0.49337\n",
      "Epoch: 120, loss: 0.38344\n",
      "Epoch: 140, loss: 0.28446\n",
      "Epoch: 160, loss: 0.20897\n",
      "Epoch: 180, loss: 0.15553\n",
      "Epoch: 200, loss: 0.11909\n",
      "Epoch: 220, loss: 0.09281\n",
      "Epoch: 240, loss: 0.07334\n",
      "Epoch: 260, loss: 0.05892\n",
      "Epoch: 280, loss: 0.04825\n",
      "Epoch: 300, loss: 0.04027\n"
     ]
    }
   ],
   "source": [
    "# normally these epochs take a lot longer \n",
    "# but with our toy data (only 3 sentences), we can do many epochs in a short time\n",
    "n_epochs = 300\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    # get all sentences and corresponding tags in the training data\n",
    "    for sentence, tags in training_data:\n",
    "        \n",
    "        # zero the gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # zero the hidden state of the LSTM, this detaches it from its history\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "        # prepare the inputs for processing by out network, \n",
    "        # turn all sentences and targets into Tensors of numerical indices\n",
    "        sentence_in = prepare_sequence(sentence, word2idx)\n",
    "        targets = prepare_sequence(tags, tag2idx)\n",
    "\n",
    "        # forward pass to get tag scores\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # compute the loss, and gradients \n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the model parameters with optimizer.step()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # print out avg loss per 20 epochs\n",
    "    if(epoch%20 == 19):\n",
    "        print(\"Epoch: %d, loss: %1.5f\" % (epoch+1, epoch_loss/len(training_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2648, -4.0755, -1.5339],\n",
      "        [-4.0535, -0.0217, -5.4881],\n",
      "        [-4.9377, -3.7223, -0.0319],\n",
      "        [-0.0791, -2.8841, -3.9033],\n",
      "        [-2.9463, -0.0595, -5.2603]], grad_fn=<LogSoftmaxBackward>)\n",
      "\n",
      "\n",
      "Predicted tags: \n",
      " tensor([0, 1, 2, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"The cheese loves the elephant\".lower().split()\n",
    "\n",
    "# see what the scores are after training\n",
    "inputs = prepare_sequence(test_sentence, word2idx)\n",
    "inputs = inputs\n",
    "tag_scores = model(inputs)\n",
    "print(tag_scores)\n",
    "\n",
    "# print the most likely tag index, by grabbing the index with the maximum score!\n",
    "# recall that these numbers correspond to tag2idx = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
    "_, predicted_tags = torch.max(tag_scores, 1)\n",
    "print('\\n')\n",
    "print('Predicted tags: \\n',predicted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-mmlab",
   "language": "python",
   "name": "open-mmlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
