{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import h5py\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import statistics\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "print(cuda_available)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_gene_function = torch.tensor((), dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data channel = subseq\n",
    "def load_file(file, flabel,subseq = 15, version = 2):\n",
    "    \n",
    "    global data_for_gene_function\n",
    "    \n",
    "    \n",
    "    f = open(file, 'r')\n",
    "    Lines = f.readlines()\n",
    "    t = 1\n",
    "    data = []\n",
    "    for line in Lines:\n",
    "        t += 1\n",
    "        line = line.split()[0:75] #75=25*3\n",
    "\n",
    "        data += line\n",
    "    \n",
    "    fl = open(flabel, 'r')\n",
    "    label = fl.readlines()[0]\n",
    "    #print (len(label))\n",
    "    \n",
    "    \n",
    "    #data\n",
    "    samples=len(label)\n",
    "    data_len= samples * subseq * 75\n",
    "    data = data[0:data_len]\n",
    "    data = [float(i) for i in data] \n",
    "    data = np.array(data)\n",
    "    data = data.reshape(samples,subseq,75)\n",
    "    \n",
    "    data_for_gene_function=data #provisoire\n",
    "    \n",
    "    if version == 2:\n",
    "        data = np.delete(data,[0,2,3,4,5,7,8,10,11,12,14],1)\n",
    "        \n",
    "\n",
    "    #label\n",
    "    label = [int(x) for x in (label)]     \n",
    "    label=np.asarray(label)\n",
    "    #print (data.shape, label.shape)\n",
    "    \n",
    "    f.close()\n",
    "\n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_path, flabel_path,subseq, version):\n",
    "    data = []\n",
    "    label = []\n",
    "    i=0\n",
    "    for filename in os.listdir(data_path):\n",
    "        data1, label1 = load_file(os.path.join(data_path,filename),os.path.join(flabel_path,filename),subseq, version)\n",
    "        data.append(torch.tensor(data1).float())\n",
    "        label.append(torch.tensor(label1))\n",
    "        i+=1\n",
    "        \n",
    "    data= torch.cat(data, 0)\n",
    "    label= torch.cat(label, 0)\n",
    "    print ('nb file = ', i)\n",
    "    \n",
    "    #print (data.shape)\n",
    "    #print (label.shape)\n",
    "    \n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_path, flabel_path, subseq, version):\n",
    "        #data loading\n",
    "        data, label = load_dataset(data_path, flabel_path, subseq, version)\n",
    "        self.x = data\n",
    "        self.y = label\n",
    "        self.n_samples = data.shape[0]\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #dataset[0]\n",
    "        return self.x[index], self.y [index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        #len dataset\n",
    "        return self.n_samples\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb file =  928\n"
     ]
    }
   ],
   "source": [
    "#load train data\n",
    "subseq = 15\n",
    "version = 2\n",
    "data_path= '/home/oussema/code/PKU-MMD/PKU_Skeleton_Renew/data/sub_train'\n",
    "flabel_path='/home/oussema/code/st-gcn/pku/pku_action_detect/train'\n",
    "\n",
    "datapku_train = MyDataset(data_path, flabel_path, subseq, version)\n",
    "dataloader_train = DataLoader(dataset=datapku_train, batch_size = 256, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb file =  130\n"
     ]
    }
   ],
   "source": [
    "#load test data\n",
    "subseq = 15\n",
    "version = 2\n",
    "data_path= '/home/oussema/code/PKU-MMD/PKU_Skeleton_Renew/data/sub_test'\n",
    "flabel_path='/home/oussema/code/st-gcn/pku/pku_action_detect/test'\n",
    "datapku_test = MyDataset(data_path, flabel_path, subseq, version )\n",
    "dataloader_test = DataLoader(dataset=datapku_test, batch_size = 1, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb file =  1\n"
     ]
    }
   ],
   "source": [
    "#load exemple data\n",
    "subseq = 15\n",
    "version = 2\n",
    "data_path= '/home/oussema/code/PKU-MMD/PKU_Skeleton_Renew/data/exemple'\n",
    "flabel_path='/home/oussema/code/st-gcn/pku/pku_action_detect/test'\n",
    "\n",
    "datapku_exemple = MyDataset(data_path, flabel_path, subseq, version)\n",
    "dataloader_exemple = DataLoader(dataset=datapku_exemple, batch_size = 1, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#afficher data\n",
    "dataiter = iter(dataloader_test)\n",
    "data = dataiter.next()\n",
    "x,y = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 75])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40817"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.shape)\n",
    "len(datapku_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL_SIZE = 3\n",
    "PAD = 1\n",
    "LEARNING_RATE = 0.1\n",
    "subseq = 4\n",
    "\n",
    "#-> CONV/FC -> BatchNorm -> ReLu(or other activation) -> Dropout -> CONV/FC ->\n",
    "\n",
    "#conv1d input [batch_size, in_channels, len]\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            \n",
    "            #nn.BatchNorm1d(subseq),\n",
    "            \n",
    "            # Layer 1: Convolution - ReLU - Max pooling - batch norm\n",
    "            nn.Conv1d(in_channels=subseq, out_channels=64, kernel_size=KERNEL_SIZE, padding=PAD),\n",
    "            #nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            #nn.Conv1d(in_channels=64, out_channels=64, kernel_size=KERNEL_SIZE, padding=PAD),\n",
    "            #nn.BatchNorm1d(64),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Dropout(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            \n",
    "            \n",
    "            # Layer 2: Convolution - ReLU - Max pooling\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=KERNEL_SIZE, padding=PAD),\n",
    "            #nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            #nn.Conv1d(in_channels=128, out_channels=128, kernel_size=KERNEL_SIZE, padding=PAD),\n",
    "            #nn.BatchNorm1d(128),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Dropout(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            \n",
    "\n",
    "            # Layer 3: Convolution - ReLU - Max pooling\n",
    "            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=KERNEL_SIZE, padding=PAD),\n",
    "            #nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            #nn.Conv1d(in_channels=256, out_channels=256, kernel_size=KERNEL_SIZE, padding=PAD),\n",
    "            #nn.BatchNorm1d(256),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Dropout(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "            \n",
    "\n",
    "\n",
    "        )\n",
    "        # Layer 5-6-7: Fully connected linear layers\n",
    "        self.fc1 = nn.Linear(256*9, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        temp = self.conv(x)\n",
    "        temp = temp.view(-1,256*9)\n",
    "        temp = self.fc1(temp)\n",
    "        temp = self.fc2(temp)\n",
    "        temp = self.fc3(temp)\n",
    "        #temp = torch.softmax(temp, dim=0)\n",
    "        return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the model: 1370178\n",
      "Classifier(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv1d(4, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=2304, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = Classifier()\n",
    "if cuda_available:\n",
    "    cnn = cnn.cuda()\n",
    "    \n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=LEARNING_RATE)\n",
    "#optimizer = torch.optim.Adam(cnn.parameters())#,weight_decay=0.04\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.NLLLoss() \n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in cnn.parameters())\n",
    "print('Number of parameters in the model: %d' % pytorch_total_params)\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  : \n",
      "train acc:  77.41580893374638\n",
      "train losses:  0.4947511018746542\n",
      "test acc:  78.38645662346572\n",
      "1  : \n",
      "train acc:  80.7384830618567\n",
      "train losses:  0.44660596442710826\n",
      "2  : \n",
      "train acc:  81.65750641217814\n",
      "train losses:  0.4326617953720353\n",
      "test acc:  78.68290173212142\n",
      "3  : \n",
      "train acc:  82.23443589487358\n",
      "train losses:  0.42447578488712423\n",
      "4  : \n",
      "train acc:  82.59318477066054\n",
      "train losses:  0.4178447266690967\n",
      "test acc:  79.7167846730529\n",
      "5  : \n",
      "train acc:  82.93927584024516\n",
      "train losses:  0.412615075682007\n",
      "6  : \n",
      "train acc:  83.10915692348689\n",
      "train losses:  0.4080743301570822\n",
      "test acc:  80.2435259818213\n",
      "7  : \n",
      "train acc:  83.35631724459545\n",
      "train losses:  0.4044608204488868\n",
      "8  : \n",
      "train acc:  83.49788481396357\n",
      "train losses:  0.4013576951551763\n",
      "test acc:  80.28762525418331\n",
      "9  : \n",
      "train acc:  83.59648246227641\n",
      "train losses:  0.39959967019411485\n",
      "10  : \n",
      "train acc:  83.60347756570401\n",
      "train losses:  0.3988146046144767\n",
      "test acc:  79.83438273268492\n",
      "11  : \n",
      "train acc:  83.7203957229939\n",
      "train losses:  0.3968768074040527\n",
      "12  : \n",
      "train acc:  83.7990073615136\n",
      "train losses:  0.3938570986454194\n",
      "test acc:  80.14062767964329\n",
      "13  : \n",
      "train acc:  83.84564138436428\n",
      "train losses:  0.392832010107134\n",
      "14  : \n",
      "train acc:  83.94423903267713\n",
      "train losses:  0.3927076431340935\n",
      "test acc:  80.48607197981234\n",
      "15  : \n",
      "train acc:  83.99953365977149\n",
      "train losses:  0.3908941908246828\n",
      "16  : \n",
      "train acc:  84.0311781752773\n",
      "train losses:  0.38990716514123586\n",
      "test acc:  80.44932258617733\n",
      "17  : \n",
      "train acc:  84.11978281869358\n",
      "train losses:  0.3889506240295876\n",
      "18  : \n",
      "train acc:  84.08747210286133\n",
      "train losses:  0.3874703125818394\n",
      "test acc:  80.86091579488938\n",
      "19  : \n",
      "train acc:  84.16108723893275\n",
      "train losses:  0.38739072877290714\n",
      "20  : \n",
      "train acc:  84.25735318610306\n",
      "train losses:  0.38549382699837864\n",
      "test acc:  81.15491094396943\n",
      "21  : \n",
      "train acc:  84.25668698577662\n",
      "train losses:  0.38501450775426405\n",
      "22  : \n",
      "train acc:  84.3049865094434\n",
      "train losses:  0.3845638242953873\n",
      "test acc:  81.12551142906142\n",
      "23  : \n",
      "train acc:  84.36128043702742\n",
      "train losses:  0.38376946056916444\n",
      "24  : \n",
      "train acc:  84.39558975383898\n",
      "train losses:  0.3822786069948722\n",
      "test acc:  81.14756106524243\n",
      "25  : \n",
      "train acc:  84.37127344192399\n",
      "train losses:  0.3823527916503034\n",
      "26  : \n",
      "train acc:  84.40924686053096\n",
      "train losses:  0.38170115910343344\n",
      "test acc:  81.02506308645907\n",
      "27  : \n",
      "train acc:  84.40391725791946\n",
      "train losses:  0.3818195779321544\n",
      "28  : \n",
      "train acc:  84.46853868958395\n",
      "train losses:  0.3801780370010044\n",
      "test acc:  81.44155621432246\n",
      "29  : \n",
      "train acc:  84.51916991439326\n",
      "train losses:  0.37991139910632027\n",
      "30  : \n",
      "train acc:  84.55647713267379\n",
      "train losses:  0.3788098936499996\n",
      "test acc:  81.24800940784478\n",
      "31  : \n",
      "train acc:  84.53782352353353\n",
      "train losses:  0.37887887974546225\n",
      "32  : \n",
      "train acc:  84.50617900802771\n",
      "train losses:  0.3789044717142403\n",
      "test acc:  81.6620525761325\n",
      "33  : \n",
      "train acc:  84.56780253822325\n",
      "train losses:  0.37823192649377896\n",
      "34  : \n",
      "train acc:  84.55980813430598\n",
      "train losses:  0.3780188050896641\n",
      "test acc:  81.11816155033442\n",
      "35  : \n",
      "train acc:  84.60344425568769\n",
      "train losses:  0.37790591499860376\n",
      "36  : \n",
      "train acc:  84.60877385829919\n",
      "train losses:  0.37676302133820977\n",
      "test acc:  81.55425435480315\n",
      "37  : \n",
      "train acc:  84.61576896172679\n",
      "train losses:  0.37634125288334314\n",
      "38  : \n",
      "train acc:  84.74601112554545\n",
      "train losses:  0.3756814445829839\n",
      "test acc:  81.4464561334738\n",
      "39  : \n",
      "train acc:  84.72102861330401\n",
      "train losses:  0.37522097642663804\n",
      "40  : \n",
      "train acc:  84.67606009126945\n",
      "train losses:  0.37531122898384167\n",
      "test acc:  81.9217482911532\n",
      "41  : \n",
      "train acc:  84.73934912228107\n",
      "train losses:  0.3750668833788751\n",
      "42  : \n",
      "train acc:  84.73568502048566\n",
      "train losses:  0.37469780631999106\n",
      "test acc:  81.52485483989514\n",
      "43  : \n",
      "train acc:  84.75533793011559\n",
      "train losses:  0.3743110762419554\n",
      "44  : \n",
      "train acc:  84.70304120449019\n",
      "train losses:  0.3749539518773352\n",
      "test acc:  81.81150011024818\n",
      "45  : \n",
      "train acc:  84.7486759268512\n",
      "train losses:  0.37437402619741883\n",
      "46  : \n",
      "train acc:  84.7556710302788\n",
      "train losses:  0.373814133755583\n",
      "test acc:  81.70860180807017\n",
      "47  : \n",
      "train acc:  84.80996635688352\n",
      "train losses:  0.37352557618921123\n",
      "48  : \n",
      "train acc:  84.81962626161688\n",
      "train losses:  0.373663094314292\n",
      "test acc:  81.96829752309087\n",
      "49  : \n",
      "train acc:  84.86792578528363\n",
      "train losses:  0.3724011526834029\n",
      "50  : \n",
      "train acc:  84.86093068185603\n",
      "train losses:  0.37304420797186094\n",
      "test acc:  81.86784918048852\n",
      "51  : \n",
      "train acc:  84.90456680323773\n",
      "train losses:  0.37179513877009773\n",
      "52  : \n",
      "train acc:  84.8602644815296\n",
      "train losses:  0.37223360813365863\n",
      "test acc:  81.70860180807017\n",
      "53  : \n",
      "train acc:  84.81562905965824\n",
      "train losses:  0.3720603387027267\n",
      "54  : \n",
      "train acc:  84.81995936178009\n",
      "train losses:  0.37151327983511184\n",
      "test acc:  82.01239679545287\n",
      "55  : \n",
      "train acc:  84.86659338463076\n",
      "train losses:  0.37123608258600527\n",
      "56  : \n",
      "train acc:  84.89024349621931\n",
      "train losses:  0.37119137209684366\n",
      "test acc:  81.70125192934317\n",
      "57  : \n",
      "train acc:  84.92788381466308\n",
      "train losses:  0.370136140149608\n",
      "58  : \n",
      "train acc:  84.90856400519637\n",
      "train losses:  0.3707819410914447\n",
      "test acc:  81.58855378886248\n",
      "59  : \n",
      "train acc:  84.95419872755738\n",
      "train losses:  0.36983943776364214\n",
      "60  : \n",
      "train acc:  84.94320642217114\n",
      "train losses:  0.3695075240863468\n",
      "test acc:  81.7576009995835\n",
      "61  : \n",
      "train acc:  84.98850804436894\n",
      "train losses:  0.37011538012391876\n",
      "62  : \n",
      "train acc:  84.98184604110456\n",
      "train losses:  0.3692910926791588\n",
      "test acc:  81.74045128255383\n",
      "63  : \n",
      "train acc:  84.90023650111588\n",
      "train losses:  0.37001030381018796\n",
      "64  : \n",
      "train acc:  85.03281036607709\n",
      "train losses:  0.3688765351148799\n",
      "test acc:  81.68410221231349\n",
      "65  : \n",
      "train acc:  84.98484394257353\n",
      "train losses:  0.3689809391599263\n",
      "66  : \n",
      "train acc:  85.01082575530462\n",
      "train losses:  0.36887458330433526\n",
      "test acc:  82.09324546144988\n",
      "67  : \n",
      "train acc:  85.0051630525299\n",
      "train losses:  0.3687129562828728\n",
      "68  : \n",
      "train acc:  85.08943739382433\n",
      "train losses:  0.36792947992733316\n",
      "test acc:  81.74535120170518\n",
      "69  : \n",
      "train acc:  85.02381666167017\n",
      "train losses:  0.3685254792686005\n",
      "70  : \n",
      "train acc:  85.04446887178975\n",
      "train losses:  0.36777099766116905\n",
      "test acc:  82.01484675502854\n",
      "71  : \n",
      "train acc:  85.08410779121282\n",
      "train losses:  0.36761964121420226\n",
      "72  : \n",
      "train acc:  85.04180407048399\n",
      "train losses:  0.3676588788196292\n",
      "test acc:  82.06874586569322\n",
      "73  : \n",
      "train acc:  85.08144298990706\n",
      "train losses:  0.36680718826657677\n",
      "74  : \n",
      "train acc:  85.09676559741514\n",
      "train losses:  0.36752109866551164\n",
      "test acc:  81.96339760393954\n",
      "75  : \n",
      "train acc:  85.10942340361747\n",
      "train losses:  0.366037142803136\n",
      "76  : \n",
      "train acc:  85.15239332467273\n",
      "train losses:  0.36666633272638904\n",
      "test acc:  81.56895411225715\n",
      "77  : \n",
      "train acc:  85.13906931814397\n",
      "train losses:  0.36586073417305537\n",
      "78  : \n",
      "train acc:  85.09809799806801\n",
      "train losses:  0.36664773417007396\n",
      "test acc:  81.88009897836686\n",
      "79  : \n",
      "train acc:  85.08877119349789\n",
      "train losses:  0.3667325755587617\n",
      "80  : \n",
      "train acc:  85.12707771226808\n",
      "train losses:  0.3664136202719838\n",
      "test acc:  81.97319744224221\n",
      "81  : \n",
      "train acc:  85.08777189300822\n",
      "train losses:  0.36692607227344154\n",
      "82  : \n",
      "train acc:  85.16904833283368\n",
      "train losses:  0.36606332199463665\n",
      "test acc:  81.64245289952716\n",
      "83  : \n",
      "train acc:  85.10675860231171\n",
      "train losses:  0.36558632539909447\n",
      "84  : \n",
      "train acc:  85.09676559741514\n",
      "train losses:  0.36572351766934574\n",
      "test acc:  82.05404610823922\n",
      "85  : \n",
      "train acc:  85.13373971553246\n",
      "train losses:  0.36588932622109666\n",
      "86  : \n",
      "train acc:  85.15239332467273\n",
      "train losses:  0.3652478973333543\n",
      "test acc:  81.83599970600486\n",
      "87  : \n",
      "train acc:  85.0944338962726\n",
      "train losses:  0.36578065439194135\n",
      "88  : \n",
      "train acc:  85.13773691749108\n",
      "train losses:  0.3649728038688365\n",
      "test acc:  81.55180439522748\n",
      "89  : \n",
      "train acc:  85.1430665201026\n",
      "train losses:  0.3650346130463247\n",
      "90  : \n",
      "train acc:  85.14806302255089\n",
      "train losses:  0.3647789687503116\n",
      "test acc:  81.59590366758948\n",
      "91  : \n",
      "train acc:  85.09176909496685\n",
      "train losses:  0.36500085104549296\n",
      "92  : \n",
      "train acc:  85.20668865127745\n",
      "train losses:  0.3641858834506302\n",
      "test acc:  81.90459857412353\n",
      "93  : \n",
      "train acc:  85.22434295992805\n",
      "train losses:  0.36457552217938793\n",
      "94  : \n",
      "train acc:  85.1537257253256\n",
      "train losses:  0.3647755833132885\n",
      "test acc:  81.58120391013549\n",
      "95  : \n",
      "train acc:  85.19869424736018\n",
      "train losses:  0.3643323889847705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96  : \n",
      "train acc:  85.23000566270278\n",
      "train losses:  0.36399339995134\n",
      "test acc:  81.80660019109685\n",
      "97  : \n",
      "train acc:  85.2479930715166\n",
      "train losses:  0.36401155022681775\n",
      "98  : \n",
      "train acc:  85.23899936710968\n",
      "train losses:  0.3639644612478722\n",
      "test acc:  81.47095572923047\n"
     ]
    }
   ],
   "source": [
    "epochs = 99\n",
    "for epoch in range (epochs):\n",
    "    correct = 0\n",
    "    train_losses = []\n",
    "    \n",
    "    cnn.train()\n",
    "    for batch_idx, (data,label) in enumerate(dataloader_train):\n",
    "        \n",
    "        if cuda_available:\n",
    "                data, label = data.cuda(), label.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = cnn(data.float())\n",
    "        loss = criterion (output, label)\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct += pred.eq(label).sum().item()\n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_acc = 100*correct/len(datapku_train)\n",
    "    print(epoch,\" : \")\n",
    "    print(\"train acc: \",train_acc)\n",
    "    print(\"train losses: \",statistics.mean(train_losses))\n",
    "    \n",
    "    if epoch%2 == 0:\n",
    "        test()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc:  84.11446211137516\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can save optimizer parameters\n",
    "torch.save(cnn.state_dict(),'/home/oussema/code/st-gcn/pku/model/CNN-1D-V2-2cls-bn-drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.load_state_dict(torch.load('/home/oussema/code/st-gcn/pku/model/CNN-1D-V2-2cls'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a test loop\n",
    "def test():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    cnn.eval()\n",
    "    with torch.no_grad():  \n",
    "        for batch_idx, (data,label) in enumerate(dataloader_test):\n",
    "            if cuda_available:\n",
    "                    data, label = data.cuda(), label.cuda()\n",
    "            net_out = cnn(data)\n",
    "            # sum up batch loss\n",
    "            test_loss += criterion(net_out, label).data\n",
    "            pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "            correct += pred.eq(label.data).sum().item()\n",
    "            #print(label)\n",
    "            #print(pred)\n",
    "            #print(\"***\")\n",
    "        \n",
    "        test_acc = 100*correct/len(datapku_test)\n",
    "        print (\"test acc: \",test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035\n",
      "test acc:  84.58975426905457\n",
      "[[16090  4021]\n",
      " [ 2269 18437]]\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "action_state = 0\n",
    "action_start = 0\n",
    "action_finish = 0\n",
    "file_name = '/home/oussema/code/PKU-MMD/PKU_Skeleton_Renew/data/st-gcn data/skeleton/S001C001P001R001A00'\n",
    "action_compteur = 0\n",
    "last_label = 0\n",
    "\n",
    "label_matrix = []\n",
    "pred_matrix = []\n",
    "\n",
    "\n",
    "cnn.eval()\n",
    "with torch.no_grad():  \n",
    "    for batch_idx, (data,label) in enumerate(dataloader_test):\n",
    "        if cuda_available:\n",
    "                    data, label = data.cuda(), label.cuda()\n",
    "        net_out = cnn(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += criterion(net_out, label).data\n",
    "        pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "        #print(batch_idx)\n",
    "        #print(label)\n",
    "        #print(pred)\n",
    "        #print(\"***\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        if pred == 1 and action_state == 0:\n",
    "            action_state = 1\n",
    "            action_start = batch_idx\n",
    "            last_label = 1\n",
    "        elif pred == 0 and action_state == 1 and last_label == 1:\n",
    "            last_label = 0\n",
    "            pred = torch.tensor([1]).cuda()\n",
    "        elif pred == 0 and action_state == 1 and last_label == 0:            \n",
    "            action_state = 0\n",
    "            action_finish = batch_idx -1\n",
    "            action_duration = action_finish-action_start+1\n",
    "            action_compteur += 1 \n",
    "            last_label = 0\n",
    "            if  batch_idx == 115 :\n",
    "                label_action = 2\n",
    "            else:\n",
    "                label_action = 1\n",
    "            #gendata(file_name+str(int(label_action))+str(action_compteur), data_for_gene_function[action_start:action_finish+1],15*action_duration)\n",
    "            #print(action_start*15,\",\",action_finish*15)\n",
    "            \n",
    "        label_matrix.append(label.cpu().numpy()[0])\n",
    "        pred_matrix.append(pred.cpu().numpy()[0])\n",
    "        \n",
    "        \n",
    "        correct += pred.eq(label.data).sum().item()\n",
    "    print(action_compteur)\n",
    "        \n",
    "    test_acc = 100*correct/len(datapku_test)\n",
    "    print (\"test acc: \",test_acc)\n",
    "    \n",
    "    conf_matrix=confusion_matrix(label_matrix,pred_matrix,labels=[0, 1])\n",
    "    print(conf_matrix)\n",
    "    #label_matrix = [i for i in label_matrix if i != 0]\n",
    "    #print(len(label_matrix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.86666666666666"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1348/15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADL class = 1\n",
    "#fall class = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gendata(outfile, data_in, nb_frame):\n",
    "    \n",
    "    #print(outfile)\n",
    "    with open(outfile, 'w',newline=\"\") as out:\n",
    "        writer = csv.writer(out,delimiter=' ')\n",
    "        \n",
    "        writer.writerow([str(nb_frame)])\n",
    "        data = data_in[0]\n",
    "        for i in range (1,int(nb_frame/15)):\n",
    "            data = np.concatenate((data, data_in[i]), axis = 0)\n",
    "\n",
    "\n",
    "        #data = data.squeeze()\n",
    "        row = [0]*3\n",
    "\n",
    "        for i in range(0,len(data)):\n",
    "            for j in range(0,len(data[0]),3):\n",
    "                row[0] = str(data[i,j])\n",
    "                row[1] = str(data[i,j+1])\n",
    "                row[2] = str(data[i,j+2])\n",
    "                writer.writerow(row)\n",
    "\n",
    "    out.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/oussema/code/PKU-MMD/PKU_Skeleton_Renew/data/st-gcn data/skeleton/S001C001P001R001A002\n",
      "(60, 75)\n"
     ]
    }
   ],
   "source": [
    "gendata('/home/oussema/code/PKU-MMD/PKU_Skeleton_Renew/data/st-gcn data/skeleton/S001C001P001R001A002',data_for_gene_function[149:153],15*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[16090  4021]\n",
      " [ 2269 18437]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = [ \"No-Action\",\"Action\"]\n",
    "plot_confusion_matrix(conf_matrix,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-mmlab",
   "language": "python",
   "name": "open-mmlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
